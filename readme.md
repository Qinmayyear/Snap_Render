# SnapRender: Background Style Clustering for E-Commerce Product Images

## ğŸ“ File Structure
SnapRender/
â”œâ”€â”€ data/
â”‚   â””â”€â”€ train/
â”‚       â”œâ”€â”€ bg1k_imgs/ # 1000 product images with full background
â”‚       â”œâ”€â”€ bg1k_masks/ # corresponding foreground-only images
â”‚       â”œâ”€â”€ bg60k_imgs_0/ # subsets of large dataset (0~4)
â”‚       â”œâ”€â”€ bg60k_imgs_1/
â”‚       â”œâ”€â”€ bg60k_imgs_2/
â”‚       â”œâ”€â”€ bg60k_imgs_3/
â”‚       â”œâ”€â”€ bg60k_imgs_4/
â”‚       â”œâ”€â”€ bg60k_masks_0/ # Corresponding foreground-only images for above subsets
â”‚       â”œâ”€â”€ bg60k_masks_1/
â”‚       â”œâ”€â”€ bg60k_masks_2/
â”‚       â”œâ”€â”€ bg60k_masks_3/
â”‚       â””â”€â”€ bg60k_masks_4/
â”‚
â”œâ”€â”€ models/
â”‚   â””â”€â”€ cvqvae.py # VQ-VAE model architecture (Encoder, Decoder, Quantizer)
â”‚
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ dataset_new.py # dataset loader
â”‚   â””â”€â”€ vq_loss.py # vector quantization loss implementation
â”‚
â”œâ”€â”€ samples_64_full/
â”‚   â”œâ”€â”€ epoch1.png
â”‚   â”œâ”€â”€ epoch30.png
â”‚   â”œâ”€â”€ epoch60.png
â”‚   â”œâ”€â”€ epoch90.png
â”‚   â”œâ”€â”€ epoch100.png
â”‚   â””â”€â”€ vqvae_without_mask.pth # trained model weights
â”‚
â”œâ”€â”€ train_without_mask.ipynb # VQ-VAE training notebook (no masking, full image reconstruction)
â”œâ”€â”€ style_cluster.ipynb # Extract latents, perform K-means, visualize with t-SNE
â””â”€â”€ README.md # Project documentation (You are here!)

## âœ… Usage Notes
- Make sure your `data/train/` directory follows the correct structure (image and mask naming must match).
  Dataset can be downloaded at: https://github.com/Whileherham/BG60k
- All training and inference is running on GPU.
- Use `train_without_mask.ipynb` to train VQ-VAE model.
- Use `style_cluster.ipynb` to perform background style clustering and t-SNE visualization.